# LOCAL AI SUITE - 100% Offline, Zero-Cost Requirements
# All models run on YOUR hardware - no API keys, no cloud services!

# ============================================================================
# CORE LOCAL AI (Required)
# ============================================================================

# Local LLM Interface (connects to Ollama)
httpx==0.26.0
aiohttp==3.9.1

# Local Vector Database (Fully Offline)
chromadb==0.4.22
duckdb==0.9.2

# Local Embeddings (Download once, use forever)
sentence-transformers==2.3.1
torch==2.2.0  # CPU version (or torch+cu118 for GPU)

# Local Document Processing
PyMuPDF==1.23.21
pikepdf==8.11.1
python-magic-bin==0.4.14  # Windows

# ============================================================================
# LOCAL SPEECH RECOGNITION (Choose one or install both)
# ============================================================================

# Option 1: Vosk (Ultra lightweight - 50MB models!)
vosk==0.3.45

# Option 2: Faster-Whisper (CPU-optimized Whisper)
faster-whisper==0.10.0

# Note: Whisper.cpp is installed separately (C++ binary)
# Download from: https://github.com/ggerganov/whisper.cpp

# ============================================================================
# LOCAL COMPUTER VISION (All offline!)
# ============================================================================

# YOLOv8 - Best face/object detection (6-52MB models)
ultralytics==8.1.11

# MediaPipe - Ultra lightweight (2MB!)
mediapipe==0.10.9

# OpenCV - Video/image processing
opencv-python==4.9.0.80

# Scene detection
scenedetect==0.6.3

# ============================================================================
# LOCAL OCR (Offline text extraction)
# ============================================================================

# Tesseract Python wrapper
pytesseract==0.3.10
# Note: Tesseract itself must be installed separately
# Windows: https://github.com/UB-Mannheim/tesseract/wiki
# Linux: sudo apt-get install tesseract-ocr

# EasyOCR (Downloads models once)
easyocr==1.7.1

# PaddleOCR (Excellent for tables)
paddleocr==2.7.0.3
paddlepaddle==2.6.0

# ============================================================================
# LOCAL DATA PROCESSING
# ============================================================================

# Fast analytics
pandas==2.2.0
numpy==1.26.3

# Local SQLite full-text search
sqlite-utils==3.36

# Fast Parquet processing
pyarrow==15.0.0

# ============================================================================
# LOCAL UI FRAMEWORKS (Optional)
# ============================================================================

# Gradio - Instant web UI
gradio==4.16.0

# Streamlit - Dashboards
streamlit==1.30.0

# ============================================================================
# UTILITIES
# ============================================================================

# Progress bars
tqdm==4.66.1

# Configuration
python-dotenv==1.0.0
pyyaml==6.0.1

# ============================================================================
# EXTERNAL TOOLS TO INSTALL SEPARATELY (One-time setup)
# ============================================================================

# 1. Ollama - Local LLM Runtime
#    Download: https://ollama.ai
#    Then run: ollama pull llama3.2:8b (or phi3:mini for faster)
#
# 2. Whisper.cpp (Optional - for fastest transcription)
#    git clone https://github.com/ggerganov/whisper.cpp
#    cd whisper.cpp && make
#    bash ./models/download-ggml-model.sh medium
#
# 3. Tesseract OCR (For pytesseract)
#    Windows: https://github.com/UB-Mannheim/tesseract/wiki
#    Linux: sudo apt-get install tesseract-ocr
#    Mac: brew install tesseract
#
# 4. FFmpeg (For video processing)
#    Windows: https://www.gyan.dev/ffmpeg/builds/
#    Linux: sudo apt-get install ffmpeg
#    Mac: brew install ffmpeg

# ============================================================================
# TOTAL DOWNLOAD SIZE (First-time setup)
# ============================================================================

# Python packages: ~2GB
# Ollama models (choose one):
#   - phi3:mini: 2.3GB (fastest, good for 8GB RAM)
#   - llama3.2:8b: 5GB (best quality, needs 16GB RAM)
#   - mistral:7b: 4GB (great reasoning)
#
# Whisper models (choose one):
#   - tiny: 75MB (basic)
#   - base: 142MB (good)
#   - medium: 1.5GB (recommended)
#   - large-v3: 3.1GB (best)
#
# Embedding models (auto-download on first use):
#   - all-MiniLM-L6-v2: 80MB
#   - Legal-BERT: 400MB (optional)
#
# Vision models (auto-download):
#   - YOLOv8-nano: 6MB
#   - MediaPipe: 2MB
#
# RECOMMENDED SETUP (16GB RAM):
# - Python packages: ~2GB
# - llama3.2:8b: 5GB
# - Whisper medium: 1.5GB
# - Embeddings: 500MB
# - Vision: 10MB
# TOTAL: ~9GB one-time download
#
# MINIMAL SETUP (8GB RAM):
# - Python packages: ~2GB
# - phi3:mini: 2.3GB
# - Whisper tiny: 75MB
# - Embeddings: 80MB
# - Vision: 6MB
# TOTAL: ~4.5GB one-time download

# ============================================================================
# AFTER INSTALLATION
# ============================================================================

# Test everything is working:
#
# 1. Start Ollama:
#    ollama serve
#
# 2. Test LLM:
#    ollama run phi3:mini "What is constitutional law?"
#
# 3. Test Python imports:
#    python -c "import chromadb, sentence_transformers, cv2, ultralytics; print('✅ All imports successful!')"
#
# 4. Start the API:
#    uvicorn app.main:app --reload --port 8000
#
# 5. Test endpoints:
#    curl http://localhost:8000/api/v1/local-ai/models/available

# ============================================================================
# ZERO ONGOING COSTS!
# ============================================================================
# After this one-time setup, you have:
# ✅ Unlimited LLM usage (Ollama)
# ✅ Unlimited transcription (Whisper)
# ✅ Unlimited semantic search (ChromaDB + sentence-transformers)
# ✅ Unlimited face detection (YOLOv8/MediaPipe)
# ✅ Unlimited OCR (Tesseract/EasyOCR/PaddleOCR)
# ✅ Complete privacy (nothing leaves your machine)
# ✅ Works 100% offline
# ✅ No API keys or subscriptions
#
# TOTAL COST: $0 forever!
